{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "############### Acknowledgement ###############\n",
    "1. set your browser download location to your desire location because all files will be downloaded to the download location setted in your browser.\n",
    "\n",
    "# Thanks -> pythonjar, MariyaSha and some other stackoverflow members...\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import json\n",
    "import platform\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = \"utf-8\"\n",
    "target_file_type = \"pdf\"\n",
    "log_file_location = \"bot_tmp.log\"\n",
    "tracker_file_location = \"files_info.json\" # this file keeps track of every downloaded file\n",
    "\n",
    "# For obvious reason ðŸ˜‰\n",
    "with open(\".secret\", encoding=encoding) as f:\n",
    "    \"\"\"\n",
    "    0 -> username,\n",
    "    1 -> password,\n",
    "    2 -> download directory (for checking)\n",
    "    3 -> chromewebdriver location (windows)\n",
    "\n",
    "    \"\"\"\n",
    "    secrets = [secret.strip() for secret in f.readlines()]\n",
    "\n",
    "with open(tracker_file_location, \"r\", encoding=encoding) as f:\n",
    "    files_info = json.load(f)[\"files\"]\n",
    "\n",
    "# already downloaded file's name in download directory\n",
    "downloaded_files = sorted(\n",
    "    [os.path.basename(f) for f in glob.glob(secrets[2] + \"/*.\" + target_file_type)]\n",
    ")\n",
    "\n",
    "# files that are registered in files_info.json\n",
    "tracked_files = sorted([(info[\"name\"], info[\"uploaded_date\"]) for info in files_info])\n",
    "\n",
    "# Ignore all alerts from the webpage\n",
    "options = webdriver.ChromeOptions()\n",
    "prefs = {\"profile.default_content_setting_values.notifications\": 2}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "# Tested on Windows & Linux\n",
    "if platform.system() == \"Windows\":\n",
    "    service = Service(secrets[3])\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "elif platform.system() == \"Linux\":\n",
    "    driver = webdriver.Chrome(\"chromedriver\", options=options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the webpage\n",
    "driver.get(\"http://www.facebook.com\")\n",
    "\n",
    "# target credentials\n",
    "username = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='email']\"))\n",
    ")\n",
    "password = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='pass']\"))\n",
    ")\n",
    "\n",
    "# enter username and password\n",
    "username.clear()\n",
    "username.send_keys(secrets[0])\n",
    "password.clear()\n",
    "password.send_keys(secrets[1])\n",
    "\n",
    "# target thesrc login button and click it\n",
    "button = (\n",
    "    WebDriverWait(driver, 2)\n",
    "    .until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[type='submit']\")))\n",
    "    .click()\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "###############################################################################################################################\n",
    "# It should be logged in! -> if you have 2fa then you have to authorize it manually and then run the remaining cells manually #\n",
    "###############################################################################################################################\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "# sleep is important because if we scrape too fast then #\n",
    "# facebook will detect the bot and block this account   #\n",
    "#########################################################\n",
    "def waitNSeconds(sleep_time=1):\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "\n",
    "def writeToFile(text):\n",
    "    with open(log_file_location, \"a\", encoding=encoding) as f:\n",
    "        f.write(text + \"\\n\")\n",
    "\n",
    "\n",
    "def binarySearch(item, itemList, tupled=False):\n",
    "    left = 0\n",
    "    right = len(itemList) - 1\n",
    "\n",
    "    while left <= right:\n",
    "        mid = int(left + (right - left) / 2)\n",
    "\n",
    "        if tupled:\n",
    "            if (\n",
    "                itemList[mid][0] == item[0] and itemList[mid][1] == item[1]\n",
    "            ):  # checking both file name and file uploaded date\n",
    "                return mid\n",
    "            elif itemList[mid][0] > item[0]:\n",
    "                right = mid - 1\n",
    "            else:\n",
    "                left = mid + 1\n",
    "        else:\n",
    "            if itemList[mid] == item:\n",
    "                return mid\n",
    "            elif itemList[mid] > item:\n",
    "                right = mid - 1\n",
    "            else:\n",
    "                left = mid + 1\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def isDownloaded(fileName, uploadDate):\n",
    "    # if either tracker file or download directory is empty then there was no previous attempt to download these files\n",
    "    # in this case all files should be downloaded\n",
    "    if not downloaded_files or not tracked_files:\n",
    "        return False\n",
    "\n",
    "    # If the file exist both in tracker file(files_info.json) & in the download location then the file has been downloaded\n",
    "    downloadedFileIndex = binarySearch(fileName, downloaded_files)\n",
    "    trackedFileIndex = binarySearch((fileName, uploadDate), tracked_files, True)\n",
    "\n",
    "    # if the file is not present in the download directory then it was not downloaded\n",
    "    if not downloadedFileIndex:\n",
    "        return False\n",
    "\n",
    "    # if the file is not present in the tracker file(files_info.json) then the file that has been requested to download didn't get to download previously (newly added file)\n",
    "    if not trackedFileIndex:\n",
    "        return False\n",
    "\n",
    "    # all files has been checked once then this shouldn't be checked anymore\n",
    "    # because there can be multiple files with the same name(in the website) and they all should be downloaded\n",
    "    # remove the found file so that the file with same name can be downloaded later on\n",
    "    tracked_files.pop(trackedFileIndex)\n",
    "    downloaded_files.pop(downloadedFileIndex)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "###################################################################\n",
    "# scroll down to load more files                                  #\n",
    "# wait 60s before determining that there is no more files to load #\n",
    "###################################################################\n",
    "def loadMoreFiles(files_to_load, identifier, timeout=60, n_scroll=1):\n",
    "    for _ in range(n_scroll):  # do this operation(scroll to load) for n times\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        seconds = 0\n",
    "        current_len = len(files_to_load[0])\n",
    "\n",
    "        ########################################################################\n",
    "        # If the first one is loaded then all others will surely get loaded    #\n",
    "        # so you don't have to check the whole length of 'files_to_load' array #\n",
    "        # but if you want you can do something like this ->                    #\n",
    "        # current_len = sum(len(i) for i in files_to_load)                     #\n",
    "        ########################################################################\n",
    "        while (current_len >= len(files_to_load[0])) and seconds < timeout:\n",
    "            time.sleep(1)\n",
    "\n",
    "            # iterate through all the files that are needed to be loaded\n",
    "            for idx, _ in enumerate(files_to_load):\n",
    "                files_to_load[idx].extend(\n",
    "                    [\n",
    "                        element\n",
    "                        for element in driver.find_elements(By.XPATH, identifier[idx])\n",
    "                        if element not in files_to_load[idx]\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            seconds += 1\n",
    "\n",
    "    return files_to_load\n",
    "\n",
    "\n",
    "def waitToFinishDownload(directory, timeout, nfiles=None):\n",
    "    \"\"\"\n",
    "    Wait for downloads to finish with a specified timeout.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    directory : str\n",
    "        The path to the folder where the files will be downloaded.\n",
    "    timeout : int\n",
    "        How many seconds until it stops waiting.\n",
    "    nfiles : int, defaults to None\n",
    "        If provided, also wait for the expected number of files.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\nWaiting for {} files to be downloaded\\n\".format(nfiles))\n",
    "\n",
    "    seconds = 0\n",
    "    dl_wait = True\n",
    "\n",
    "    while dl_wait and seconds < timeout:\n",
    "        time.sleep(0.5)  # check every 0.5s\n",
    "        dl_wait = False\n",
    "        files = os.listdir(directory)\n",
    "\n",
    "        # if nfiles and len(files) != nfiles:\n",
    "        # if nfiles and len(files) < nfiles:\n",
    "        #     dl_wait = True\n",
    "\n",
    "        for fname in files:\n",
    "            if fname.endswith(\n",
    "                \".crdownload\"\n",
    "            ):  # as partial downloaded files will be of \".crdownload\" extension for chromium based browsers\n",
    "                dl_wait = True\n",
    "                break\n",
    "\n",
    "        seconds += 0.5\n",
    "\n",
    "    if seconds >= timeout:\n",
    "        seconds = -1\n",
    "        print(\n",
    "            \"Your connection is too slow or you are not connected! Try again later. Closing the connection...\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"Continuing after {}s...\\n\".format(seconds))\n",
    "\n",
    "    return seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waitNSeconds(5) # enable this if this script is fully automated for your case\n",
    "driver.get(\"https://www.facebook.com/groups/201623576939858/files/\")\n",
    "\n",
    "download_thread_count = (\n",
    "    3  # this value will ensure how many downloads will happen concurrently\n",
    ")\n",
    "\n",
    "wait = WebDriverWait(driver, 10) # to wait until the element is ready -> Explicit Waits\n",
    "\n",
    "\"\"\"\n",
    "# targets identifiers                                                            #\n",
    "# this identifiers will change continuously so update it according to your needs #\n",
    "\n",
    "\"\"\"\n",
    "download_button_cssSelector = \"a[href*='https://www.facebook.com/download/']\"\n",
    "fileOption_xpath = \"//div[@aria-label='File options']\"  # by default finds 15 per-scroll\n",
    "fileName_xpath = \"//span[@class='d2edcug0 hpfvmrgz qv66sw1b c1et5uql lr9zc1uh a8c37x1j fe6kdd0r mau55g9w c8b282yb keod5gw0 nxhoafnm aigsh9s9 d3f4x2em iv3no6db jq4qci2q a3bd9o3v lrazzd5p oo9gr5id hzawbc8m']\"  # find 15 per-scroll\n",
    "fileTypeDate_xpath = \"//span[@class='d2edcug0 hpfvmrgz qv66sw1b c1et5uql lr9zc1uh a8c37x1j fe6kdd0r mau55g9w c8b282yb keod5gw0 nxhoafnm aigsh9s9 d9wwppkn iv3no6db e9vueds3 j5wam9gi b1v8xokw oo9gr5id hzawbc8m']\"  # find 30 per-scroll\n",
    "\n",
    "###########################################################\n",
    "# NOT NEEDED -> as it doesn't sort by file type reliably ðŸ˜‘\n",
    "###########################################################\n",
    "# sortButtons_xpath = \"//div[@class='l9j0dhe7 du4w35lb j83agx80 pfnyh3mw taijpn5t bp9cbjyn owycx6da btwxx1t3 kt9q3ron ak7q8e6j isp2s0ed ri5dt5u2 rt8b4zig n8ej3o3l agehan2d sk4xxmp2 rq0escxv d1544ag0 tw6a2znq tdjehn4e tv7at329']\" # find 3 per-scroll\n",
    "\n",
    "# sortButtons = wait.until(\n",
    "#     EC.presence_of_all_elements_located((By.XPATH, sortButtons_xpath))\n",
    "# )\n",
    "\n",
    "# # sort by file_type (PDF at the top in my case)\n",
    "# driver.execute_script(\"arguments[0].click();\", sortButtons[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j, k = 0, 1\n",
    "registered_files_count = sum(\n",
    "    1 for _ in open(log_file_location, encoding=encoding)\n",
    ")  # total files registered in the log file\n",
    "\n",
    "##################################\n",
    "# grabbing initial loaded target #\n",
    "##################################\n",
    "file_option_buttons = wait.until(\n",
    "    EC.presence_of_all_elements_located((By.XPATH, fileOption_xpath))\n",
    ")\n",
    "file_names = wait.until(EC.presence_of_all_elements_located((By.XPATH, fileName_xpath)))\n",
    "file_types_and_dates = wait.until(\n",
    "    EC.presence_of_all_elements_located((By.XPATH, fileTypeDate_xpath))\n",
    ")\n",
    "\n",
    "for idx, button in enumerate(file_option_buttons):\n",
    "    try:\n",
    "        _name = file_names[idx].text\n",
    "        _type = file_types_and_dates[j].text\n",
    "        _date = file_types_and_dates[k].text\n",
    "\n",
    "        # as 'file_types_and_dates' contains both file-type and date\n",
    "        j += 2\n",
    "        k += 2\n",
    "\n",
    "        # Scroll after 15th button click to load more files (as by default 15 files loads per scroll)\n",
    "        if (idx + 1) % 15 == 0:\n",
    "            [file_option_buttons, file_names, file_types_and_dates] = loadMoreFiles(\n",
    "                [file_option_buttons, file_names, file_types_and_dates],\n",
    "                [fileOption_xpath, fileName_xpath, fileTypeDate_xpath],\n",
    "            )\n",
    "\n",
    "        ############################################################################\n",
    "        # Download pdf files only                                                  #\n",
    "        # Cannot check this before the scroll because                              #\n",
    "        # there is a possibility to have more than one page worth of non-pdf files #\n",
    "        ############################################################################\n",
    "        if not _type == target_file_type.upper():\n",
    "            continue\n",
    "\n",
    "        ######### TODO -> check this functions\n",
    "        # isDownloaded()\n",
    "        # waitToFinishDownload()\n",
    "        ##############\n",
    "\n",
    "        ####################################\n",
    "        # To skip already downloaded files #\n",
    "        ####################################\n",
    "        if isDownloaded(_name):\n",
    "            print(\n",
    "                \"Skipping... {}/{} ---> {}\".format(\n",
    "                    idx + 1, len(file_option_buttons), _name\n",
    "                )\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        ##########################################################################################################\n",
    "        # Waiting after every 'download_thread_count' downloads request                                      #\n",
    "        # we have to wait for the files to be downloaded, if we continue without it there maybe some files       #\n",
    "        # that couldn't be downloaded on time (before the link expire) and later on those files can't be resumed #\n",
    "        ##########################################################################################################\n",
    "        if (idx + 1) % download_thread_count == 0:\n",
    "            download_time = waitToFinishDownload(\n",
    "                secrets[2], 600, registered_files_count\n",
    "            )  # waiting for 600s before closing the connection for slow/no internet\n",
    "\n",
    "            if download_time == -1:\n",
    "                break  # Stoping the Bot because of a network failure\n",
    "        \n",
    "        #####################################################\n",
    "        # If everything is OK then initiating file download #\n",
    "        #####################################################\n",
    "        driver.execute_script(\n",
    "            \"arguments[0].click();\", button\n",
    "        )  # Clicking the download button\n",
    "        # wait.until(EC.element_to_be_clickable(button)).click() # this was giving me -> ElementClickInterceptedException\n",
    "\n",
    "        waitNSeconds(0.8)\n",
    "\n",
    "        try:\n",
    "            download_link = wait.until(\n",
    "                EC.presence_of_element_located(\n",
    "                    (By.CSS_SELECTOR, download_button_cssSelector)\n",
    "                )\n",
    "            )\n",
    "\n",
    "            driver.execute_script(\n",
    "                \"arguments[0].target='_self';\", download_link\n",
    "            )  # to prevent it from opening into a new tab\n",
    "            driver.execute_script(\"arguments[0].click();\", download_link)\n",
    "\n",
    "            registered_files_count += 1  # Keeping track of the downloaded files\n",
    "\n",
    "        except:\n",
    "            writeToFile(\n",
    "                \"***** Warning: No download link found at {} *****\".format(idx + 1)\n",
    "            )\n",
    "\n",
    "        # Updating log\n",
    "        log = '\"{}\" --- \"{}\" --- \"{}\"'.format(_name, _type, _date)\n",
    "        writeToFile(log)\n",
    "\n",
    "        print(\"{} --- {} - {}\".format(_name, _date, len(file_option_buttons)))\n",
    "\n",
    "        #################################################################\n",
    "        # waiting at least 2s for safety sake ðŸ˜…                        #\n",
    "        # waiting (1.2+0.8+calculation_time) -> 2s+ after each download #\n",
    "        #################################################################\n",
    "        waitNSeconds(1.2)\n",
    "\n",
    "        ############## NOT TESTED YET ####################\n",
    "        # file_option_buttons.pop(idx)\n",
    "        # file_names.pop(idx)\n",
    "        # file_types_and_dates.pop(j)\n",
    "        # file_types_and_dates.pop(k)\n",
    "        ############## NOT TESTED YET ####################\n",
    "\n",
    "    except Exception as e:\n",
    "        log = \"***** ERROR at {}, date: {}: {} *****\".format(idx + 1, _date, e)\n",
    "\n",
    "        print(log)\n",
    "        writeToFile(log)\n",
    "\n",
    "# driver.close() # not closing because I had to run this cell multiple times during test\n",
    "print(\"\\nCompleted. Total scrapped file:\", registered_files_count)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86591fc59d41e1aa02175333bc0753628aa66026b46d3e558ecd962b0f627551"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
