{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('bot_tmp.log', encoding='utf-8') as f:\n",
    "#     lines = [line.split(\" --- \") for line in f.readlines()]\n",
    "\n",
    "#     res = {'files': []}\n",
    "\n",
    "#     for idx, line in enumerate(lines):\n",
    "#         entry = {\n",
    "#             'id': idx + 1,\n",
    "#             'type': line[1].strip()[1:-1],\n",
    "#             'name': line[0].strip()[1:-1],\n",
    "#             'uploaded_date': line[2].strip()[1:-1]\n",
    "#         }\n",
    "\n",
    "#         res['files'].append(entry)\n",
    "\n",
    "#     with open('files_info.json', 'w', encoding='utf-8') as f:\n",
    "#         json.dump(res, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING -> This doesn't work reliable.... It deletes data that are matched!!!!\n",
    "# import json\n",
    "\n",
    "# auxiliaryList = []\n",
    "\n",
    "# with open('../files_info.json', 'r+', encoding='utf-8') as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "#     for info in data[\"files\"]:\n",
    "#         info[\"id\"] = 1\n",
    "\n",
    "#     for idx, info in enumerate(data[\"files\"]):\n",
    "#         if info not in auxiliaryList:\n",
    "#             auxiliaryList.append(info)\n",
    "\n",
    "#     for idx, info in enumerate(auxiliaryList):\n",
    "#         info[\"id\"] = idx + 1\n",
    "\n",
    "#     print(len(data['files']))\n",
    "    \n",
    "# with open('../files_info.json', 'w', encoding='utf-8') as f:\n",
    "#     data[\"files\"] = auxiliaryList\n",
    "#     json.dump(data, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import json\n",
    "import string\n",
    "import platform\n",
    "import unicodedata\n",
    "from selenium import webdriver\n",
    "from json.decoder import JSONDecodeError\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "# Packages & Libraries\n",
    "import json\n",
    "from json.decoder import JSONDecodeError\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from constants import (\n",
    "    secrets,\n",
    "    encoding,\n",
    "    target_file_type,\n",
    "    log_file_location,\n",
    "    normalization_form,\n",
    "    explicit_wait_time,\n",
    "    tracker_file_location,\n",
    "    network_failure_timeout,\n",
    ")\n",
    "\n",
    "from helperFunctions import (\n",
    "    login,\n",
    "    updateLog,\n",
    "    waitNSeconds,\n",
    "    downloadFile,\n",
    "    loadMoreFiles,\n",
    "    appendFilesInfo,\n",
    "    initializeWebpage,\n",
    "    checkDownloadStatus,\n",
    "    initializeWebDriver,\n",
    "    waitToFinishDownload,\n",
    "    getExistingFilesInfo,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    " targets identifiers -> this identifiers will change continuously so update it according to your needs \n",
    "\n",
    "\"\"\"\n",
    "download_button_cssSelector = \"a[href*='https://www.facebook.com/download/']\"\n",
    "permalink_xpath = \"//a[contains(@href, 'https://www.facebook.com/groups/201623576939858/permalink/')]\"  # by default finds 15 per-scroll\n",
    "fileOption_xpath = \"//div[@aria-label='File options']\"  # by default finds 15 per-scroll\n",
    "\n",
    "# Target identifiers\n",
    "# They change too often so they have to be present here\n",
    "fileName_xpath = \"//span[@class='d2edcug0 hpfvmrgz qv66sw1b c1et5uql lr9zc1uh a8c37x1j fe6kdd0r mau55g9w c8b282yb keod5gw0 nxhoafnm aigsh9s9 d3f4x2em iv3no6db jq4qci2q a3bd9o3v lrazzd5p oo9gr5id hzawbc8m']\"  # find 15 per-scroll\n",
    "fileTypeDate_xpath = \"//span[@class='d2edcug0 hpfvmrgz qv66sw1b c1et5uql lr9zc1uh a8c37x1j fe6kdd0r mau55g9w c8b282yb keod5gw0 nxhoafnm aigsh9s9 d9wwppkn iv3no6db e9vueds3 j5wam9gi b1v8xokw oo9gr5id hzawbc8m']\"  # find 30 per-scroll\n",
    "\n",
    "driver, wait = initializeWebDriver()\n",
    "login(driver, wait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareString(s1, s2):\n",
    "    # string will be normalized before coming here\n",
    "    # s1 = unicodedata.normalize(normalization_form, s1)\n",
    "    # s2 = unicodedata.normalize(normalization_form, s2)\n",
    "\n",
    "    # Removing whitespace in the string before comparing\n",
    "    # because when file saves in the machine it seems to add whitepsaces after '-'\n",
    "    # remove = string.punctuation + string.whitespace\n",
    "    remove = string.whitespace\n",
    "    mapping = {ord(c): None for c in remove}\n",
    "\n",
    "    return s1.translate(mapping) == s2.translate(mapping)\n",
    "\n",
    "\n",
    "def getExistingFilesInfo():\n",
    "    with open(tracker_file_location, \"r\", encoding=encoding) as f:\n",
    "        try:\n",
    "            files_info = json.load(f)[\"files\"]\n",
    "        except JSONDecodeError:\n",
    "            files_info = []\n",
    "\n",
    "    tracked_files = sorted(\n",
    "        [\n",
    "            [\n",
    "                unicodedata.normalize(normalization_form, info[\"uploaded_date\"]),\n",
    "                unicodedata.normalize(normalization_form, info[\"name\"]),\n",
    "            ]\n",
    "            for info in files_info\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return [], tracked_files\n",
    "\n",
    "\n",
    "def binarySearch(item, itemList, multipleCheck=False):\n",
    "    left = 0\n",
    "    right = len(itemList) - 1\n",
    "\n",
    "    while left <= right:\n",
    "        mid = left + (right - left) // 2\n",
    "\n",
    "        if multipleCheck:\n",
    "            \"\"\"\n",
    "            Sorted By: uploaded date\n",
    "\n",
    "            If permalink exist for the file then check:\n",
    "                0 uploaded date\n",
    "                1 permalink of the post\n",
    "                2 file name\n",
    "            If not then check:\n",
    "                0 uploaded date\n",
    "                2 file name\n",
    "\n",
    "            \"\"\"\n",
    "            if compareString(itemList[mid][0], item[0]) and compareString(\n",
    "                itemList[mid][1], item[1]\n",
    "            ):\n",
    "                return mid\n",
    "            elif itemList[mid][0] > item[0]:\n",
    "                right = mid - 1\n",
    "            else:\n",
    "                left = mid + 1\n",
    "        else:\n",
    "            if compareString(itemList[mid], item):\n",
    "                return mid\n",
    "            elif itemList[mid] > item:\n",
    "                right = mid - 1\n",
    "            else:\n",
    "                left = mid + 1\n",
    "\n",
    "    return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j, k = 0, 1\n",
    "\n",
    "# Grabbing initial loadeded target\n",
    "try:\n",
    "    file_option_buttons = wait.until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, fileOption_xpath))\n",
    "    )\n",
    "    file_names = wait.until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, fileName_xpath))\n",
    "    )\n",
    "    file_types_and_dates = wait.until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, fileTypeDate_xpath))\n",
    "    )\n",
    "\n",
    "    # This is the unique identifier of a post/file\n",
    "    post_permalink = wait.until(\n",
    "        EC.presence_of_all_elements_located((By.XPATH, permalink_xpath))\n",
    "    )\n",
    "except TimeoutException:\n",
    "    print(\"XPATH's identifier (class names) has changed again! ðŸ¤¯\")\n",
    "\n",
    "\n",
    "\"\"\" MAIN LOOP \"\"\"\n",
    "for idx, button in enumerate(file_option_buttons):\n",
    "    try:\n",
    "        _name = file_names[idx].text\n",
    "        _type = file_types_and_dates[j].text\n",
    "        _date = file_types_and_dates[k].text\n",
    "        _permalink = post_permalink[idx].get_attribute(\"href\")\n",
    "\n",
    "        # as 'file_types_and_dates' contains both file-type and date\n",
    "        j += 2\n",
    "        k += 2\n",
    "\n",
    "        # Scrolling after it reaches at the end of the list to load more files\n",
    "        if button is file_option_buttons[-1]:\n",
    "            [\n",
    "                file_option_buttons,\n",
    "                file_names,\n",
    "                file_types_and_dates,\n",
    "                post_permalink,\n",
    "            ] = loadMoreFiles(\n",
    "                driver,\n",
    "                [file_option_buttons, file_names, file_types_and_dates, post_permalink],\n",
    "                [fileOption_xpath, fileName_xpath, fileTypeDate_xpath, permalink_xpath],\n",
    "            )\n",
    "\n",
    "            updateLog(\"\\nTotal Loaded Files: {}\\n\".format(len(file_option_buttons)))\n",
    "\n",
    "        \"\"\"\n",
    "        Download pdf files only\n",
    "        Cannot check this before the scroll because\n",
    "        here is a possibility to have more than one page worth of non-pdf files\n",
    "        \n",
    "        \"\"\"\n",
    "        if not _type == target_file_type.upper():\n",
    "            updateLog(\n",
    "                '\\nðŸ˜ª Skipping ({}): \"{} --- {}\", ðŸ¤” Reason: FILE_TYPE: \"{}\"'.format(\n",
    "                    idx + 1, _name, _date, _type\n",
    "                )\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        updateLog(\"\\n*** ERROR at {}, date: {} ***\\n--> {}\\n\".format(_name, _date, e))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88901c317dc70daf78dfd7a773a6525c4dfeb1fa8e4740ded1ab17187716d835"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
